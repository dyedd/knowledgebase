# æ‰©æ•£æ¨¡å‹

## ç®€ä»‹

æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelsï¼‰åœ¨ä¸åŒçš„é¢†åŸŸå’Œæ–‡çŒ®ä¸­å¯èƒ½æœ‰ä¸åŒçš„åç§°ã€‚å…¶ä¸­ä¸€äº›å¸¸è§çš„åç§°åŒ…æ‹¬å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆddpmï¼‰ã€åŸºäºåˆ†æ•°çš„ç”Ÿæˆæ¨¡å‹ï¼ˆscore-based generative modelsï¼‰å’Œç”Ÿæˆæ‰©æ•£è¿‡ç¨‹ï¼ˆgenerative diffusion processesï¼‰ç­‰ç­‰ã€‚å¦å¤–ï¼Œæœ‰äº›äººä¹Ÿå°†å®ƒä»¬ç§°ä¸ºåŸºäºèƒ½é‡çš„æ¨¡å‹ï¼ˆEBMsï¼‰ï¼Œä»æŠ€æœ¯ä¸Šæ¥è¯´ï¼Œå®ƒä»¬å¯ä»¥è¢«å½’ç±»ä¸ºè¿™ä¸ªæ¨¡å‹å®¶æ—çš„ä¸€ä¸ªç‰¹ä¾‹ã€‚ä½†æ˜¯æœ€è´´åˆ‡çš„æè¿°åº”è¯¥æ˜¯**åŸºäºåˆ†æ•°åŒ¹é…æ¨¡å‹(score-based generative models)**çš„æƒ³æ³•ï¼Œå¹¶ä½¿ç”¨äº†åŸºäºéšæœºå¾®åˆ†æ–¹ç¨‹(SDEs)çš„å½¢å¼ä¸»ä¹‰ã€‚

æ‰©æ•£æ¨¡å‹çš„æ„å»ºè¿‡ç¨‹ï¼šé¦–å…ˆï¼Œå®ƒæè¿°äº†å°†æ•°æ®è½¬åŒ–ä¸ºå™ªå£°çš„é€æ­¥è¿‡ç¨‹ï¼Œå¹¶è®­ç»ƒç¥ç»ç½‘ç»œæ¥å­¦ä¹ è¿™ä¸ªè¿‡ç¨‹ã€‚åœ¨æ¯ä¸ªæ­¥éª¤ä¸­ï¼Œéƒ½ä¼šæœ‰å¸¦æœ‰å™ªå£°çš„è¾“å…¥ï¼Œç„¶åé€šè¿‡å¡«å……è¢«å™ªéŸ³æ©ç›–çš„ä¿¡æ¯ï¼Œä½¿å™ªå£°å‡å°ä¸€äº›ã€‚æœ€ç»ˆï¼Œé€šè¿‡å¤šæ¬¡ä»çº¯å™ªå£°å¼€å§‹å¹¶é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œå°±å¯ä»¥ç”¨è¿™ç§æ–¹æ³•ç”Ÿæˆæ•°æ®ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬ä¸»è¦ç»“åˆğŸ¤—Diffusersè¿™ä¸ªåº“æ¥æŒ–æ˜æˆ‘ä»¬å¼ºå¤§çš„æ‰©æ•£æ¨¡å‹ã€‚

ğŸ¤—Diffusers çš„æ ¸å¿ƒ API è¢«åˆ†ä¸ºä¸‰ä¸ªä¸»è¦éƒ¨åˆ†:

1. **ç®¡é“**: ä»é«˜å±‚å‡ºå‘è®¾è®¡çš„å¤šç§ç±»å‡½æ•°ï¼Œæ—¨åœ¨ä»¥æ˜“éƒ¨ç½²çš„æ–¹å¼ï¼Œèƒ½å¤Ÿåšåˆ°å¿«é€Ÿé€šè¿‡ä¸»æµé¢„è®­ç»ƒå¥½çš„æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆæ ·æœ¬ã€‚ä¸€èˆ¬äººåªç”¨è¿™ä¸ªå°±è¡Œäº†ã€‚
2. **æ¨¡å‹**: è®­ç»ƒæ–°çš„æ‰©æ•£æ¨¡å‹æ—¶ç”¨åˆ°çš„ä¸»æµç½‘ç»œæ¶æ„ï¼Œ*e.g.* [UNet](https://arxiv.org/abs/1505.04597).
3. **è°ƒåº¦å™¨(or ç®¡ç†å™¨ ï¼Œæˆ‘æ›´å–œæ¬¢å«è°ƒåº¦å™¨)**: åœ¨ *æ¨ç†* ä¸­ä½¿ç”¨å¤šç§ä¸åŒçš„æŠ€å·§æ¥ä»å™ªå£°ä¸­ç”Ÿæˆå›¾åƒï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥ç”Ÿæˆåœ¨ *è®­ç»ƒ* ä¸­æ‰€éœ€çš„å¸¦å™ªå›¾åƒã€‚æˆ‘ä»¬åœ¨è®­ç»ƒä¸­ï¼Œå–å‡ºçœŸå®å›¾åƒç„¶åå¯¹å®ƒä»¬å¢æ·»å™ªå£°ï¼Œåœ¨è¿™ä¹‹åæŠŠå¸¦å™ªçš„å›¾ç‰‡é€å…¥æ¨¡å‹ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œæˆ‘ä»¬å°†ç”¨æ¨¡å‹çš„é¢„æµ‹å€¼æ¥ä¸æ–­è¿­ä»£å»é™¤è¿™äº›å™ªç‚¹ã€‚

ä¾‹å¦‚ï¼Œè¿™å°±æ˜¯ä¸€ä¸ªå¾ˆç®€å•çš„piplineï¼š

```python
from diffusers import DDPMPipeline

def make_grid(images, size=64):
    """Given a list of PIL images, stack them together into a line for easy viewing"""
    output_im = Image.new("RGB", (size * len(images), size))
    for i, im in enumerate(images):
        output_im.paste(im.resize((size, size)), (i * size, 0))
    return output_im

# Load the butterfly pipeline
butterfly_pipeline = DDPMPipeline.from_pretrained(
    "johnowhitaker/ddpm-butterflies-32px"
).to(device)

# Create 8 images
images = butterfly_pipeline(batch_size=8).images

# View the result
make_grid(images)
```

`num_inference_steps`å’Œ`guidance_scale`åˆ†åˆ«æ˜¯é‡‡æ ·æ¬¡æ•°å’Œæ¨¡å‹åŒ¹é…ç¨‹åº¦

## æ‰©æ•£ç†è®ºåŸºç¡€

### ä¸€ç§ç®€å•çš„CorruptionæŸåè¿‡ç¨‹

è¯´æŸåæœ‰ç‚¹é™Œç”Ÿï¼Œè¿™ä¸ªè¿‡ç¨‹å®é™…ä¸Šå°±æ˜¯åŠ å™ªå£°çš„æµç¨‹ã€‚

è¿™é‡Œä»‹ç»ä¸€ä¸ªå¾ˆç®€å•çš„æ§åˆ¶åŠ å™ªçš„æ•°é‡ï¼Œæˆ‘ä»¬è®¾ä¸€ä¸ªå…¬å¼ï¼š$ (1-amount)*x + amount*noise$ï¼Œè¿™ä¸ªå…¬å¼æ˜¯æƒ³è¯´å¦‚æœamount = 0ï¼Œæˆ‘ä»¬å°†è¿”å›è¾“å…¥è€Œä¸è¿›è¡Œä»»ä½•æ›´æ”¹ã€‚å¦‚æœamount è¾¾åˆ° 1ï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°è¿”å›å™ªå£°ï¼Œè€Œæ²¡æœ‰è¾“å…¥ x çš„ç—•è¿¹ã€‚è¯•æƒ³ï¼Œå¦‚æœamountæ˜¯ä¸€ä¸ªå°æ•°ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯åœ¨æœ‰å’Œæ— ä¹‹é—´ï¼Œç±»ä¼¼äºé¢œè‰²ä¸­çš„ä¸é€æ˜åº¦ï¼Œæ‰€ä»¥åŠ ç™¾åˆ†ä¹‹å‡ çš„å™ªå£°è¿™ä¸ªå…¬å¼å°±èƒ½å¾ˆç®€å•çš„å¸®æˆ‘ä»¬å®ç°ã€‚

é€šè¿‡ä»¥è¿™ç§æ–¹å¼å°†è¾“å…¥ä¸å™ªå£°æ··åˆï¼Œæˆ‘ä»¬å¯ä»¥å°†è¾“å‡ºä¿æŒåœ¨ç›¸åŒçš„èŒƒå›´å†…ï¼ˆ0 åˆ° 1ï¼‰ã€‚

```python
def corrupt(x, amount):
  """Corrupt the input `x` by mixing it with noise according to `amount`"""
  noise = torch.rand_like(x)
  amount = amount.view(-1, 1, 1, 1) # Sort shape so broadcasting works
  return x*(1-amount) + noise*amount 
```

æˆ‘ä»¬ä½¿ç”¨éšæœºç”Ÿæˆxç»´åº¦ä¸€æ ·çš„å™ªå£°æ•°æ®ï¼Œä¾‹å¦‚æˆ‘ä»¬è®¾xçš„ç»´åº¦æ˜¯(8,1,28,28)ï¼Œé‚£ä¹ˆnoiseçš„ç»´åº¦ä¹Ÿæ˜¯(8,1,28,28)ï¼Œamoutè¿™é‡Œä½¿ç”¨viewè¿›è¡Œå˜å½¢ï¼Œä¸ºä»€ä¹ˆè¿™é‡Œè¦å¹¿æ’­ï¼Œæˆ‘ä»¬éœ€è¦ç»“åˆä¸‹é¢çš„ä»£ç æ¥çœ‹ï¼š

```python
# Plotting the input data
fig, axs = plt.subplots(2, 1, figsize=(12, 5))
axs[0].set_title('Input data')
axs[0].imshow(torchvision.utils.make_grid(x)[0], cmap='Greys')

# Adding noise
amount = torch.linspace(0, 1, x.shape[0]) # Left to right -> more corruption
noised_x = corrupt(x, amount)

# Plotting the noised version
axs[1].set_title('Corrupted data (-- amount increases -->)')
axs[1].imshow(torchvision.utils.make_grid(noised_x)[0], cmap='Greys');
```

amountæ˜¯å¹²ä»€ä¹ˆçš„ï¼Ÿæˆ‘ä»¬ä½¿ç”¨torch.linspaceå°†0åˆ°1å¹³åˆ†æˆ8ä»½ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰8å¼ è¾“å…¥çš„å›¾åƒï¼Œè¿™æ ·å¯ä»¥çœ‹åˆ°æ¯ä¸€å¼ å›¾åƒä»æ— åˆ°é€æ¸åŠ å™ªåˆ°å®Œæ•´å™ªå£°æ˜¯æ€ä¹ˆæ ·çš„ã€‚amoutçš„ç»´åº¦åº”è¯¥æ˜¯(8)ï¼Œå€¼ä¸ºtensor([0.0000, 0.1429, 0.2857, 0.4286, 0.5714, 0.7143, 0.8571, 1.0000])ï¼Œè¿™æ ·å®ƒçš„ç»´åº¦å’Œxä¸ä¸€æ ·ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±è¦å¹¿æ’­æ¥è®¡ç®—äº†ã€‚å¹¿æ’­åçš„ç»´åº¦æ˜¯(8,1,1,1)ã€‚

![image-20231118211615826](../_images/image-20231118211615826.png)

### åŸºç¡€UNet

UNetå¸¸å¸¸ç”¨æ¥æ¥æ”¶ä¸€ä¸ªå°ºå¯¸çš„å™ªå£°å›¾åƒï¼Œ**å¹¶è¾“å‡ºç›¸åŒå½¢çŠ¶çš„é¢„æµ‹**ã€‚

UNetç”±ä¸€ä¸ªâ€œå‹ç¼©è·¯å¾„â€å’Œä¸€ä¸ªâ€œæ‰©å±•è·¯å¾„â€ç»„æˆã€‚â€œå‹ç¼©è·¯å¾„â€ä¼šä½¿é€šè¿‡è¯¥è·¯å¾„çš„æ•°æ®è¢«å‹ç¼©ï¼Œè€Œé€šè¿‡â€œæ‰©å±•è·¯å¾„â€ä¼šå°†æ•°æ®æ‰©å±•å›åŸå§‹ç»´åº¦ï¼ˆç±»ä¼¼äºè‡ªåŠ¨ç¼–ç å™¨ï¼‰ã€‚æ¨¡å‹ä¸­çš„æ®‹å·®è¿æ¥ä¹Ÿå…è®¸ä¿¡æ¯å’Œæ¢¯åº¦åœ¨ä¸åŒå±‚çº§ä¹‹é—´æµåŠ¨ã€‚

![image-20231118204041225](../_images/image-20231118204041225.png)

```python
class BasicUNet(nn.Module):
    """A minimal UNet implementation."""
    def __init__(self, in_channels=1, out_channels=1):
        super().__init__()
        self.down_layers = torch.nn.ModuleList([ 
            nn.Conv2d(in_channels, 32, kernel_size=5, padding=2),
            nn.Conv2d(32, 64, kernel_size=5, padding=2),
            nn.Conv2d(64, 64, kernel_size=5, padding=2),
        ])
        self.up_layers = torch.nn.ModuleList([
            nn.Conv2d(64, 64, kernel_size=5, padding=2),
            nn.Conv2d(64, 32, kernel_size=5, padding=2),
            nn.Conv2d(32, out_channels, kernel_size=5, padding=2), 
        ])
        self.act = nn.SiLU() # The activation function
        self.downscale = nn.MaxPool2d(2)
        self.upscale = nn.Upsample(scale_factor=2)

    def forward(self, x):
        h = []
        for i, l in enumerate(self.down_layers):
            print(i,l)
            x = self.act(l(x)) # Through the layer and the activation function
            if i < 2: # For all but the third (final) down layer:
              h.append(x) # Storing output for skip connection
              x = self.downscale(x) # Downscale ready for the next layer
              
        for i, l in enumerate(self.up_layers):
            print(i,l)
            if i > 0: # For all except the first up layer
              x = self.upscale(x) # Upscale
              x += h.pop() # Fetching stored output (skip connection)
            x = self.act(l(x)) # Through the layer and the activation function
            
        return x
```

è¿™é‡Œçš„ç¤ºä¾‹ä»£ç æ˜¯ä¸€ä¸ªç®€å•æ¨¡å‹ï¼Œæ¥æ”¶äº†ä¸€ä¸ª28pxçš„å•è‰²å›¾åƒã€‚æˆ‘ä»¬è®¾`x = torch.rand(8, 1, 28, 28)`

UNetåœ¨ä¸‹é‡‡æ ·æ—¶å€™ï¼Œæ¥æ”¶å›¾åƒä¼ å…¥ä¸‹è¡Œè·¯å¾„down_layersï¼ˆå…¶ä¸­æœ‰3ä¸ªå·ç§¯å±‚ï¼‰ï¼Œåœ¨å·ç§¯åä½¿ç”¨SiLUæ¿€æ´»å‡½æ•°ã€‚åœ¨3ä¸ªå·ç§¯å±‚é‡Œåªæœ‰åä¸¤ä¸ªç”¨äºè·³è·ƒè¿æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨æœ€å¤§æ± åŒ–è¿›è¡Œä¸‹é‡‡æ ·ã€‚

æˆ‘è®¤ä¸ºç»´åº¦å˜åŒ–ï¼Œå¯ä»¥æ¯”å›¾åƒæ›´ç›´è§‚åœ°çœ‹æµç¨‹å˜åŒ–ï¼š

ç¬¬1æ¬¡è¾“å…¥:  `torch.Size([8, 1, 28, 28])` 

ç¬¬1æ¬¡å·ç§¯:  `torch.Size([8, 32, 28, 28]) `ï¼Œä»1é€šé“å˜æˆ32é€šé“

ç¬¬1æ¬¡æ¿€æ´»å‡½æ•°:  `torch.Size([8, 32, 28, 28]) `,æ¿€æ´»å‡½æ•°ä¸æ”¹å˜ç»´åº¦

ç¬¬1ä¸‹é‡‡æ ·:  `torch.Size([8, 32, 14, 14])`,ä½¿ç”¨2Ã—2æ± åŒ–ï¼Œç›¸å½“äºæŠŠå›¾åƒç¼©å°2å€ã€‚

ç¬¬2æ¬¡è¾“å…¥:  `torch.Size([8, 32, 14, 14]) `æŠŠç¬¬ä¸€æ¬¡ä¸‹é‡‡æ ·çš„ç»“æœè¾“å…¥

ç¬¬2æ¬¡å·ç§¯:  `torch.Size([8, 64, 14, 14]) `,ç»§ç»­æ‰©å¤§æˆ64é€šé“

ç¬¬2æ¬¡æ¿€æ´»å‡½æ•°:  `torch.Size([8, 64, 14, 14])`ï¼Œè¿™ä¸ªæ—¶å€™çš„ç»“æœè¦ä¿å­˜å¥½ï¼Œç”¨äºä¸Šé‡‡æ ·çš„ç¬¬ä¸€ä¸ªç»“æœç›¸åŠ 

ç¬¬2ä¸‹é‡‡æ ·: ` torch.Size([8, 64, 7, 7]) `ç»§ç»­ç¼©å°å°ºå¯¸

ç¬¬3æ¬¡è¾“å…¥:  `torch.Size([8, 64, 7, 7]) `

ç¬¬3æ¬¡å·ç§¯:  `torch.Size([8, 64, 7, 7]) `

ç¬¬3æ¬¡æ¿€æ´»å‡½æ•°:  `torch.Size([8, 64, 7, 7])`ï¼Œç”¨äºä¸Šé‡‡æ ·çš„ç¬¬äºŒä¸ªç»“æœç›¸åŠ 

> æˆ‘ä»¬å‘ç°ï¼Œæˆ‘ä»¬åˆ†åˆ«åŠ å…¥ç¬¬2æ¬¡å’Œç¬¬3æ¬¡çš„æ¿€æ´»å‡½æ•°ç»“æœï¼Œä½†æ˜¯ä¾æ¬¡æ‹¿æ¥ä½¿ç”¨ï¼Œä¹Ÿå°±æ˜¯å…ˆè¿›åå‡ºçš„é˜Ÿåˆ—å…³ç³»ï¼Œåœ¨pythonä¸­æˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨åˆ—è¡¨ï¼Œæ¯ä¸€æ¬¡åœ¨å°¾éƒ¨æ·»åŠ ï¼Œç„¶åæ¯æ¬¡ç›¸åŠ ï¼Œä½¿ç”¨popå‡½æ•°æŠŠå¤´éƒ¨åˆ é™¤ã€‚

åœ¨ä¸‹é‡‡æ ·æ—¶å€™ï¼Œè¾“å…¥å…ˆç»è¿‡ä¸Šè¡Œè·¯å¾„çš„ç¬¬ä¸€ä¸ªå·ç§¯å±‚+æ¿€æ´»å‡½æ•°ï¼Œç„¶åå…ˆè¿›è¡Œä¸Šé‡‡æ ·åŠ ä¸Šè·³è·ƒçš„ç»“æœï¼Œå†ä¼ å…¥ç¬¬äºŒå±‚å·ç§¯ï¼Œç¬¬ä¸‰æ¬¡ä¹Ÿæ˜¯å…ˆä¸Šé‡‡æ ·åŠ è·³è·ƒåŠ ç¬¬ä¸‰å±‚å·ç§¯ã€‚

ç¬¬1è¾“å…¥:  `torch.Size([8, 64, 7, 7]) `

ç¬¬1å·ç§¯: ` torch.Size([8, 64, 7, 7]) `ï¼Œç¬¬ä¸€æ¬¡å·ç§¯ä¸æ”¹å˜é€šé“

ç¬¬1æ¿€æ´»å‡½æ•°å:  `torch.Size([8, 64, 7, 7]) `

ç¬¬2è¾“å…¥:  `torch.Size([8, 64, 7, 7]) `

ç¬¬2ä¸Šé‡‡æ ·:  `torch.Size([8, 64, 14, 14]) `ï¼Œå¼€å§‹æ‰©å¤§2å€å›¾åƒ

ç¬¬2è·³è·ƒå:  `torch.Size([8, 64, 14, 14]) `ä¸ä¸‹é‡‡æ ·çš„ç¬¬2æ¬¡æ¿€æ´»å‡½æ•°ç»“æœç›´æ¥ç›¸åŠ 

ç¬¬2å·ç§¯:  `torch.Size([8, 32, 14, 14]) `ï¼Œç¼©å°é€šé“

ç¬¬2æ¿€æ´»å‡½æ•°å:  `torch.Size([8, 32, 14, 14]) `

ç¬¬3è¾“å…¥:  `torch.Size([8, 32, 14, 14]) `

ç¬¬3ä¸Šé‡‡æ ·: ` torch.Size([8, 32, 28, 28]) `

ç¬¬3è·³è·ƒå:  `torch.Size([8, 32, 28, 28]) `

ç¬¬3å·ç§¯:  `torch.Size([8, 1, 28, 28]) `

ç¬¬3æ¿€æ´»å‡½æ•°å: ` torch.Size([8, 1, 28, 28])`

è¯¥ç½‘ç»œæœ‰`sum([p.numel() for p in net.parameters()])`=309057ä¸ªå‚æ•°

### è®­ç»ƒæ¨¡å‹

æ¥ä¸‹æ¥æˆ‘ä»¬ç»™å®šä¸€ä¸ªæŸåçš„è¾“å…¥noisy_xï¼ˆå³ä¸Šé¢çš„corruptå‡½æ•°ï¼Œä½ å¯ä»¥æƒ³è±¡æŠŠä¸Šé¢é€æ¸æœ‰å™ªå£°çš„8å¼ å›¾ç»™UNetè¿›è¡Œè®­ç»ƒï¼‰ï¼Œæ¨¡å‹åº”è¯¥è¾“å‡ºå®ƒå¯¹åŸæœ¬xçš„æœ€ä½³çŒœæµ‹ã€‚æˆ‘ä»¬å°†é€šè¿‡å‡æ–¹è¯¯å·®å°†é¢„æµ‹ä¸çœŸå®å€¼è¿›è¡Œæ¯”è¾ƒã€‚

ä¸»è¦æµç¨‹æ˜¯ï¼š

- è·å–ä¸€æ‰¹æ•°æ®
- æ·»åŠ éšæœºå™ªå£°
- å°†æ•°æ®è¾“å…¥æ¨¡å‹
- å°†æ¨¡å‹é¢„æµ‹ä¸å¹²å‡€å›¾åƒè¿›è¡Œæ¯”è¾ƒï¼Œä»¥è®¡ç®—loss
- æ›´æ–°æ¨¡å‹çš„å‚æ•°ã€‚

```python
# Dataloader (you can mess with batch size)
batch_size = 128
train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# How many runs through the data should we do?
n_epochs = 3

# Create the network
net = BasicUNet()
net.to(device)

# Our loss function
loss_fn = nn.MSELoss()

# The optimizer
opt = torch.optim.Adam(net.parameters(), lr=1e-3) 

# Keeping a record of the losses for later viewing
losses = []

# The training loop
for epoch in range(n_epochs):

    for x, y in train_dataloader:

        # Get some data and prepare the corrupted version
        x = x.to(device) # Data on the GPU
        noise_amount = torch.rand(x.shape[0]).to(device) # Pick random noise amounts
        noisy_x = corrupt(x, noise_amount) # Create our noisy x

        # Get the model prediction
        pred = net(noisy_x)

        # Calculate the loss
        loss = loss_fn(pred, x) # How close is the output to the true 'clean' x?

        # Backprop and update the params:
        opt.zero_grad()
        loss.backward()
        opt.step()

        # Store the loss for later
        losses.append(loss.item())

    # Print our the average of the loss values for this epoch:
    avg_loss = sum(losses[-len(train_dataloader):])/len(train_dataloader)
    print(f'Finished epoch {epoch}. Average loss for this epoch: {avg_loss:05f}')

# View the loss curve
plt.plot(losses)
plt.ylim(0, 0.1);
```

æˆ‘ä»¬è¿˜å¯ä»¥å¯è§†åŒ–ä»¥ä¸åŒçš„æ•°é‡æŸåæ•°æ®ï¼Œç„¶åå–‚è¿›æ¨¡å‹è·å¾—é¢„æµ‹æ¥è§‚å¯Ÿç»“æœï¼š

```python
#@markdown Visualizing model predictions on noisy inputs:

# Fetch some data
x, y = next(iter(train_dataloader))
x = x[:8] # Only using the first 8 for easy plotting

# Corrupt with a range of amounts
amount = torch.linspace(0, 1, x.shape[0]) # Left to right -> more corruption
noised_x = corrupt(x, amount)

# Get the model predictions
with torch.no_grad():
  preds = net(noised_x.to(device)).detach().cpu()

# Plot
fig, axs = plt.subplots(3, 1, figsize=(12, 7))
axs[0].set_title('Input data')
axs[0].imshow(torchvision.utils.make_grid(x)[0].clip(0, 1), cmap='Greys')
axs[1].set_title('Corrupted data')
axs[1].imshow(torchvision.utils.make_grid(noised_x)[0].clip(0, 1), cmap='Greys')
axs[2].set_title('Network Predictions')
axs[2].imshow(torchvision.utils.make_grid(preds)[0].clip(0, 1), cmap='Greys');
```

clipå°†å¼ é‡ä¸­çš„å€¼é™åˆ¶äº0-1ä¹‹é—´ã€‚è¿™å°±æ˜¯ä¸€ä¸ªå½’ä¸€åŒ–ã€‚

![image-20231118212847282](../_images/image-20231118212847282.png)

ä½ å¯ä»¥çœ‹åˆ°ï¼Œå™ªå£°åŠ çš„å°‘çš„éƒ½èƒ½å¾ˆå¥½çš„é¢„æµ‹ï¼Œå½“å›¾åƒè¶Šæ¥è¶Šæ¨¡ç³Šçš„æ—¶å€™ï¼ŒUNetå°±è¯†åˆ«ä¸äº†äº†ã€‚

### é‡‡æ ·

å¥½ï¼Œæ¨¡ç³Šçš„å›¾åƒè¯†åˆ«ä¸äº†æ€ä¹ˆåŠï¼Ÿ

è¿™æ—¶å€™å°±éœ€è¦é‡‡æ ·äº†ï¼Œæˆ‘ä»¬çš„ç›®çš„æ˜¯èƒ½è¯†åˆ«æ·»åŠ äº†100%å™ªå£°çš„å›¾åƒï¼Œé‚£ä¹ˆå®ƒç°åœ¨éƒ½æ˜¯å™ªå£°æˆ‘ä»¬æ€ä¹ˆè¯†åˆ«ï¼Œç®€å•æ¥è¯´ï¼Œæˆ‘ä»¬è¦ä»å®ƒåŸæ¥çš„æ•°æ®ä¸Šå–éƒ¨åˆ†æ•°æ®ç»™æœ‰å™ªå£°çš„å›¾åƒèåˆï¼Œå®¹é‡æ˜¯ä¸€å®šçš„ï¼Œä½†åŸæ•°æ®è¶Šæ¥è¶Šå¤šæ—¶å€™ï¼Œå™ªå£°ä¾¿ä¼šè¶Šæ¥è¶Šå°ã€‚æˆ‘ä»¬å¯ä»¥æƒ³è±¡ï¼Œå½“æˆ‘ä»¬å¯¹ä¸€ä¸ªçŸ¥è¯†ç‚¹å¾ˆæ¨¡ç³Šçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸€ç‚¹ä¸€ç‚¹å­¦ä¹ å·²æœ‰çš„çŸ¥è¯†ï¼Œæˆ‘ä»¬æ˜¯ä¸æ˜¯å¯¹è¿™ä¸ªæ¨¡ç³Šçš„ç‚¹è¶Šæ¥è¶Šæ¸…æ™°äº†ï¼Ÿ

é‡‡æ ·å°±æ˜¯è¿™æ ·çš„è¿‡ç¨‹ã€‚

å‡è®¾æˆ‘ä»¬å¯¹ä¸€ä¸ªçŸ¥è¯†åŸæ¥æœ‰5å¤„ä¸æ‡‚ï¼Œæˆ‘ä»¬å­¦ä¹ 5æ¬¡ï¼Œæ¯æ¬¡å­¦ä¹ ä¸€ä¸ªç‚¹ã€‚

ç¬¬ä¸€æ¬¡æˆ‘ä»¬å…ˆæ¥è§¦çŸ¥è¯†ï¼Œå‡è®¾æˆ‘ä»¬å­¦äº†ç¬¬ä¸€ä¸ªçŸ¥è¯†ç‚¹ï¼Œé‚£ä¹ˆå¯¹äºæ¨¡ç³Šå¤„æˆ‘ä»¬è¿˜æœ‰4å¤„æ²¡æœ‰æ˜ç™½ã€‚

ç¬¬äºŒæ¬¡ç»§ç»­å­¦ä¹ ï¼Œå‡è®¾æˆ‘ä»¬å°±æŒæ¡äº†çŸ¥è¯†çš„$\frac{2}{5}$ï¼Œé‚£ä¹ˆå¯¹äºæ¨¡ç³Šå¤„æˆ‘ä»¬è¿˜æœ‰3/5æ²¡æœ‰æ˜ç™½ã€‚

...ä¾æ¬¡åˆ°

ç¬¬äº”æ¬¡å­¦ä¹ ï¼Œæˆ‘ä»¬æŒæ¡äº†çŸ¥è¯†çš„100%ï¼Œå­¦ä¹ å®Œæ¯•ã€‚

å½“ç„¶çœŸå®é‡‡æ ·çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸æ˜¯ç¥ç«¥ï¼Œè¿™ç§çŸ¥è¯†å¸æ”¶ç¨‹åº¦å¤ªå¯æ€•äº†ï¼Œæ›´å¤šæ—¶å€™æ™®é€šäººå¯èƒ½å¯¹çŸ¥è¯†ç‚¹ä¸æ˜¯æ¯æ¬¡éƒ½èƒ½å®Œå…¨æŒæ¡ï¼Œè¿™ä¸ªçŸ¥è¯†ç‚¹ç®€å•ï¼Œæˆ‘ä»¬ä¸€å­¦å°±é€šï¼Œä¸‹ä¸ªçŸ¥è¯†ç‚¹ï¼Œåœ¨è€å¸ˆè¯¾å ‚ä¸Šï¼Œæˆ‘ä»¬åªå¸æ”¶äº†éƒ¨åˆ†ï¼Œç„¶åè€å¸ˆåˆå»è®²æ–°çš„å»äº†ï¼Œæ‰€ä»¥ä½ å¯¹è¿™ä¸ªéš¾ç‚¹å¹¶ä¸æ˜¯å®Œå…¨æŒæ¡çš„ã€‚

ä»¥æ­¤ï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿæ­£å¸¸æƒ…å†µï¼Œæˆ‘ä»¬æŠŠ**â€çŸ¥è¯†å­˜é‡â€œ**ç§°ä¸ºxï¼ŒæŠŠ**æ¨¡ç³Šç¨‹åº¦**ç§°ä¸ºpredï¼ˆä½ æ€»æ˜¯ä»æ— æ³•ç†è§£å˜æˆèƒ½ç†è§£ï¼Œæˆ‘ä»¬è¦é¢„æµ‹ä½ å¯¹çŸ¥è¯†çš„æŒæ¡ç¨‹åº¦å¦‚ä½•ï¼‰ã€‚

æˆ‘ä»¬æ…¢æ…¢å­¦ä¹ ï¼Œç¬¬ä¸€æ¬¡å­¦ä¹ åï¼Œæˆ‘ä»¬å¯¹ä¸€ä¸ªçŸ¥è¯†æŒæ¡äº†$\frac{4}{5}$ï¼Œé‚£ä¹ˆä½ çš„æ¨¡ç³Šç¨‹åº¦å°±ä»1å˜æˆäº†åŸæ¥çš„$\frac{1}{5}$ï¼Œæ³¨æ„è¿™é‡Œæ¨¡ç³Šç¨‹åº¦æ˜¯ä½ ä»ä¸ç†è§£å˜æˆç†è§£çš„ç¨‹åº¦ï¼ŒåŸæ¥çš„$\frac{1}{5}$å·²ç»ç†è§£å¥½å¤šäº†ã€‚

è¿™æ—¶å€™æˆ‘ä»¬æ¥è¡¡é‡ä¸€ä¸‹æˆ‘ä»¬ä¸‹é¢è¦å­¦çš„çŸ¥è¯†$x_1$=$\frac{4}{5}x+\frac{1}{5}pred$ï¼Œè¿™æ˜¯ä»€ä¹ˆæ„æ€å‘¢ï¼ŸçŸ¥è¯†æ˜¯ä¸€ç§ç´¯åŠ è¿‡ç¨‹ï¼Œä½ ä¹Ÿå¯ä»¥è®¤ä¸ºï¼Œæˆ‘ä»¬ç¬¬ä¸€æ¬¡å­¦ä¹ çš„çŸ¥è¯†ï¼Œåœ¨åé¢çš„å­¦ä¹ è¿˜è¦ç”¨åˆ°çš„ï¼Œç„¶è€Œåé¢çš„$\frac{1}{5}$ä¸ç†è§£ï¼Œä½ ä¹Ÿè¦å­¦ä¹ ã€‚

ç¬¬äºŒæ¬¡å­¦ä¹ ï¼Œæˆ‘ä»¬è¦è½¬å‘è¿™ä¸ªæ–°çš„çŸ¥è¯†äº†ï¼ŒåŒç†ç°åœ¨çš„çŸ¥è¯†å­˜é‡åº”è¯¥æ˜¯$x_2$=$\frac{3}{4}x_1+\frac{1}{4}pred_1$ï¼Œè¿™ä¸ªçŸ¥è¯†å¯èƒ½æ›´éš¾äº†ã€‚

ä¾æ¬¡è¿›è¡Œï¼Œç›´åˆ°ç¬¬äº”æ¬¡ï¼Œå¯¹$x_5$ï¼Œæ¨¡ç³Šç¨‹åº¦å¯èƒ½è¿˜æœ‰ï¼Œä½†æ€»æ¯”ç¬¬ä¸€æ¬¡å­¦ä¹ æ—¶å€™æ¸…æ¥šäº†ã€‚

è¿™é‡Œçš„æµç¨‹å¯ä»¥å†™æˆä»£ç ï¼š

```python
#@markdown Sampling strategy: Break the process into 5 steps and move 1/5'th of the way there each time:
n_steps = 5
x = torch.rand(8, 1, 28, 28).to(device) # Start from random
step_history = [x.detach().cpu()]
pred_output_history = []

for i in range(n_steps):
    with torch.no_grad(): # No need to track gradients during inference
        pred = net(x) # Predict the denoised x0
    pred_output_history.append(pred.detach().cpu()) # Store model output for plotting
    mix_factor = 1/(n_steps - i) # How much we move towards the prediction
    x = x*(1-mix_factor) + pred*mix_factor # Move part of the way there
    step_history.append(x.detach().cpu()) # Store step for plotting

fig, axs = plt.subplots(n_steps, 2, figsize=(9, 4), sharex=True)
axs[0,0].set_title('x (model input)')
axs[0,1].set_title('model prediction')
for i in range(n_steps):
    axs[i, 0].imshow(torchvision.utils.make_grid(step_history[i])[0].clip(0, 1), cmap='Greys')
    axs[i, 1].imshow(torchvision.utils.make_grid(pred_output_history[i])[0].clip(0, 1), cmap='Greys')
```

æˆ‘ä»¬å¯ä»¥ç»“åˆä¸‹é¢å›¾åƒå¯ä»¥çœ‹åˆ°æ¸…æ™°å¾—å˜æ‡‚äº†ï¼š

![image-20231118215515651](../_images/image-20231118215515651.png)

å¤šåƒåƒè¡¥å“ï¼Œå¤šå¤šè¿åŠ¨ï¼Œå°‘äº›ä¸å¥åº·çš„äº‹æƒ…å•Šï¼Œä½ å°±å˜å¾—è¶Šæ¥è¶Šèªæ˜ï¼Œè¶Šæ¥è¶Šå¸…æ°”ï¼Œæˆ–è€…å‹¤èƒ½è¡¥æ‹™ï¼Œå¤šè®­ç»ƒä¼šï¼Œä½ å¯¹çŸ¥è¯†çš„æ¨¡ç³Šç¨‹åº¦åªä¼šè¶Šæ¥è¶Šä½äº†ï¼Œå“ˆå“ˆå“ˆã€‚

## ä¸ DDPM åšæ¯”è¾ƒ

ä¸Šé¢å‘€ï¼Œåªæ˜¯ç®€å•çš„ä½çº§ä½é¢ï¼Œè€ŒDDPMå®ƒæ˜¯ä¸€å¶ä¸€ä¸–ç•Œï¼Œå®ƒæ˜¯ä¸€ä¸ªé«˜çº§ä½é¢ï¼Œå®ƒæŒç®¡å¤šä¸ªä½çº§ä½é¢ã€‚è§„åˆ™æ³•å…¸åˆä¸å¤ªç›¸åŒï¼Œæ¯”ä½çº§ä½é¢é«˜çº§å¤ªå¤šäº†ã€‚

å…·ä½“è¡¨ç°åœ¨ï¼š

1. è¯¥æ¨¡å‹é€šè¿‡è°ƒèŠ‚timestepæ¥è°ƒèŠ‚å™ªå£°æ°´å¹³, å…¶ä¸­tä½œä¸ºä¸€ä¸ªé™„åŠ å‚æ•°ä¼ å…¥å‰å‘è¿‡ç¨‹ä¸­ã€‚åŸæ¥çš„UNetåªè¦ä¼ å…¥å™ªå£°ï¼Œä¸‹é¢æˆ‘ä»¬è¿˜è¦ä¼ å…¥æ—¶é—´æ­¥é•¿ã€‚
2. æŸåè¿‡ç¨‹çš„å¤„ç†æ–¹å¼ä¸åŒï¼Œå‰é¢åªæ˜¯ä¸€ä¸ªç®€å•çš„åŠ å™ªå‡½æ•°
3. æœ‰è®¸å¤šé‡‡æ ·ç­–ç•¥
4. diffusers`UNet2DModel`æ¯”æˆ‘ä»¬çš„BasicUNetæ›´å…ˆè¿›
5. è®­ç»ƒç›®æ ‡ä¸åŒï¼ŒåŒ…æ‹¬é¢„æµ‹å™ªå£°è€Œä¸æ˜¯å»å™ªå›¾åƒã€‚è¿™é‡Œä¸ºä»€ä¹ˆè¿™ä¹ˆè¯´ï¼Ÿåœ¨å‰é¢çš„ç¤ºä¾‹ä»£ç ï¼Œæˆ‘ä»¬æ˜¯è¾“å…¥å™ªå£°ï¼Œç„¶åä¸çœŸå®æ•°æ®è¿›è¡Œå¯¹æ¯”ï¼Œæ³¨æ„äº†ï¼Œå¦‚æœDDPMåªæ˜¯æ¢å¤åŸå›¾ï¼Œé‚£å®ƒå‡­ä»€ä¹ˆç”Ÿæˆä¸åŒå›¾åƒã€‚æˆ‘ä»¬çš„ä¸»è¦ç›®çš„å˜æˆï¼Œæˆ‘ä»¬ä¸æ˜¯æŠŠå®ƒè¿˜åŸï¼Œè€Œæ˜¯é€šè¿‡å™ªå£°ï¼Œå½±å“è¯†åˆ«å®ƒçš„æ ·å­ï¼Œæ‰€ä»¥æˆ‘ä»¬åº”è¯¥è®­ç»ƒå¸¦æœ‰å™ªå£°çš„å›¾åƒã€‚

### æ¨¡å‹

UNet2DModel æ¨¡å‹æ¯”ä¸Šé¢çš„åŸºæœ¬ UNet æœ‰è®¸å¤šæ”¹è¿›ï¼š

- å¯¹æ¯ä¸ªblocksçš„è¾“å…¥è¿›è¡Œäº†ç»„æ ‡å‡†åŒ–ï¼Œgroup normalization
- ä½¿ç”¨äº†Dropoutï¼Œè®©è®­ç»ƒæ›´å¹³æ»‘
- æ¯ä¸ªå—å¤šäº†resnetå±‚ï¼
- æ³¨æ„åŠ›æœºåˆ¶æ¥äº†ï¼ï¼ˆé€šå¸¸ä»…ç”¨äºè¾ƒä½åˆ†è¾¨ç‡çš„å—ï¼Œæ¥å‡å°‘å†…å­˜æ¶ˆè€—ï¼‰
- å¢åŠ æ–°çš„è¾“å…¥æ¡ä»¶ï¼šæ—¶é—´æ­¥é•¿ï¼ˆtimestepï¼‰
- å…·æœ‰å¯å­¦ä¹ å‚æ•°çš„ä¸‹é‡‡æ ·å’Œä¸Šé‡‡æ ·å—

```
model = UNet2DModel(
    sample_size=28,           # the target image resolution
    in_channels=1,            # the number of input channels, 3 for RGB images
    out_channels=1,           # the number of output channels
    layers_per_block=2,       # how many ResNet layers to use per UNet block
    block_out_channels=(32, 64, 64), # Roughly matching our basic unet example
    down_block_types=( 
        "DownBlock2D",        # a regular ResNet downsampling block
        "AttnDownBlock2D",    # a ResNet downsampling block with spatial self-attention
        "AttnDownBlock2D",
    ), 
    up_block_types=(
        "AttnUpBlock2D", 
        "AttnUpBlock2D",      # a ResNet upsampling block with spatial self-attention
        "UpBlock2D",          # a regular ResNet upsampling block
      ),
)
print(model)
```

æ‰“å°ç»“æœå¤ªé•¿äº†ï¼Œå“ã€‚

å®ƒçš„å‚æ•°é‡å˜æˆ1707009ï¼ˆ170ä¸‡ï¼‰ï¼ŒåŸæ¥æ˜¯309057ï¼ˆ30ä¸‡ï¼‰

æ¦‚æ‹¬æ¥è¯´:

- è¾“å…¥æ¨¡å‹ä¸­çš„å›¾ç‰‡ç»è¿‡å‡ ä¸ªç”± ResNetLayeræ„æˆçš„å±‚ï¼Œå…¶ä¸­æ¯å±‚éƒ½ä½¿å›¾ç‰‡å°ºå¯¸å‡åŠã€‚åŸºç¡€çš„æ˜¯ç”¨æ± åŒ–æ–¹å¼
- ä¹‹ååœ¨ç»è¿‡åŒæ ·æ•°é‡çš„å±‚æŠŠå›¾ç‰‡å‡é‡‡æ ·ã€‚
- å…¶ä¸­è¿˜æœ‰å¯¹ç‰¹å¾åœ¨ç›¸åŒä½ç½®çš„ä¸Šã€ä¸‹é‡‡æ ·å±‚æ®‹å·®è¿æ¥æ¨¡å—ã€‚

è¿™é‡Œ`down_block_types`å¯¹åº”ä¸‹é‡‡æ ·æ¨¡å— (ä¸‹å›¾ä¸­ç»¿è‰²éƒ¨åˆ†), è€Œ`up_block_types`å¯¹åº”ä¸Šé‡‡æ ·æ¨¡å— (ä¸‹å›¾ä¸­çº¢è‰²éƒ¨åˆ†):

![img](../_images/68747470733a2f2f68756767696e67666163652e636f2f64617461736574732f68756767696e67666163652f646f63756d656e746174696f6e2d696d616765732f7265736f6c76652f6d61696e2f756e65742d6d6f64656c2e706e67.png)

### æŸåè¿‡ç¨‹

![img](../_images/174349667-04e9e485-793b-429a-affe-096e8199ad5b.png)

*å›¾æ¥è‡ª DDPM è®ºæ–‡ (https://arxiv.org/abs/2006.11239)ã€‚*

DDPMè®ºæ–‡æè¿°äº†ä¸€ä¸ªä¸ºæ¯ä¸ªâ€œtimestepâ€æ·»åŠ å°‘é‡å™ªå£°çš„æŸåè¿‡ç¨‹ã€‚ ä¸ºæŸäº›timestepç»™å®š $x_{t-1}$  ,æˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ä¸ªå™ªå£°ç¨ç¨å¢åŠ çš„  $x_t$:
$$
q(\mathbf{x}_t \vert \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x} _{t-1}, \beta_t\mathbf{I}) \quad q(\mathbf{x}_{1:T} \vert \mathbf{x}_0) = \prod^T_{t=1} q (\mathbf{x}_t \vert \mathbf{x}_{t-1})
$$
$q(\mathbf{x}_t \vert \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t\mathbf{I})$è¿™è¡¨ç¤ºåœ¨ç»™å®šå‰ä¸€ä¸ªtimestepçš„çŠ¶æ€ $x_{t-1}$ çš„æ¡ä»¶ä¸‹ï¼Œå½“å‰timestepçš„çŠ¶æ€ $x_{t}$ æœä»å‡å€¼ä¸º$\sqrt{1 - \beta_t} \mathbf{x} _{t-1} $ï¼Œæ–¹å·®ä¸º$\beta_t\mathbf{I}$çš„å¤šå…ƒæ­£æ€åˆ†å¸ƒã€‚è¿™é‡Œçš„$\beta_t$é€šå¸¸æ˜¯ä¸€ä¸ªè¡¨ç¤ºç³»ç»ŸåŠ¨åŠ›å­¦ç‰¹æ€§æˆ–å™ªå£°ç¨‹åº¦çš„å‚æ•°ã€‚

$q(\mathbf{x}_{1:T} \vert \mathbf{x}_0) = \prod^T_{t=1} q (\mathbf{x}_t \vert \mathbf{x}_{t-1})$è¿™è¡¨ç¤ºæ•´ä¸ªçŠ¶æ€åºåˆ—$\mathbf{x}_{1:T}$åœ¨ç»™å®šåˆå§‹çŠ¶æ€$x_0$çš„æ¡ä»¶ä¸‹ï¼Œå¯ä»¥è¢«åˆ†è§£ä¸ºæ¯ä¸€æ—¶åˆ»çš„æ¡ä»¶æ¦‚ç‡çš„è¿ä¹˜ç§¯ã€‚æ¢å¥è¯è¯´ï¼Œè¿™ä¸ªå…¬å¼è¡¨ç¤ºæ•´ä¸ªçŠ¶æ€åºåˆ—çš„è”åˆåˆ†å¸ƒå¯ä»¥è¢«åˆ†è§£ä¸ºå„ä¸ªæ—¶åˆ»çš„æ¡ä»¶åˆ†å¸ƒçš„è¿ä¹˜ç§¯ï¼Œè¿™æ­£æ˜¯é©¬å°”å¯å¤«é“¾çš„æ€§è´¨æ‰€åœ¨ï¼Œå³å½“å‰çŠ¶æ€ä»…ä¾èµ–äºå‰ä¸€ä¸ªçŠ¶æ€ã€‚

æˆ‘ä»¬ç»™ $x_{t-1}$ ä¸€ä¸ª $\sqrt{1 - \beta_t}$ ç³»æ•°ï¼Œç„¶ååŠ ä¸Šå¸¦æœ‰ $\beta_t$ ç³»æ•°çš„å™ªå£° ã€‚è¿™ä¸ª $\beta$  æ˜¯æ ¹æ®è°ƒåº¦å™¨ä¸ºæ¯ä¸ª t å®šä¹‰çš„ï¼Œå†³å®šæ¯ä¸€ä¸ªè¿­ä»£å‘¨æœŸä¸­æ·»åŠ å¤šå°‘å™ªå£°ã€‚ 

ä½†ä¸Šé¢çš„å…¬å¼ä½ ä¼šå‘ç°ï¼Œæˆ‘ä»¬è¦è®¡ç®—å¥½å¤šæ¬¡ï¼Œä»$x_1$ç®—åˆ°$x_2$ä¸€ç›´ç®—åˆ°$x_n$ã€‚æ‰€ä»¥æˆ‘ä»¬ç”¨ä¸€ä¸ªä¸€æ­¥åˆ°ä½çš„å…¬å¼ï¼š

$\begin{aligned}q(\mathbf{x}_t \vert \mathbf{x}_0) &= \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, \sqrt{(1 - \bar{\alpha}_t)} \mathbf{I})\end{aligned}$ where $\bar{\alpha}_t = \prod_{i=1}^T \alpha_i$ and $\alpha_i = 1-\beta_i$

è¿™ä¸ªå…¬å¼è¡¨ç¤ºäº†åœ¨ç»™å®šåˆå§‹çŠ¶æ€ $x_0$çš„æ¡ä»¶ä¸‹ï¼Œå½“å‰tiemsteptçš„çŠ¶æ€$x_t$çš„æ¦‚ç‡åˆ†å¸ƒã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒè¡¨ç¤º$x_t$ åœ¨å‡å€¼ä¸º $\sqrt{\bar{\alpha}_t} \mathbf{x}_0$ï¼Œæ–¹å·®ä¸º$\sqrt{(1 - \bar{\alpha}_t)} \mathbf{I}$ çš„å¤šå…ƒæ­£æ€åˆ†å¸ƒä¸­çš„æ¦‚ç‡åˆ†å¸ƒã€‚å…¶ä¸­ï¼Œ$\bar{\alpha}_t$æ˜¯ä¸€ä¸ªå…³äºæ—¶é—´çš„ç´¯ç§¯å‚æ•°ï¼Œç”±æ‰€æœ‰æ—¶é—´æ­¥é•¿å†…çš„ $\alpha_i$ä¹˜ç§¯å¾—åˆ°ï¼Œè€Œ $\alpha_i$åˆ™æ˜¯ä¸$\beta_i$ç›¸å…³çš„å‚æ•°ã€‚

åœ¨è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œ$\sqrt{\bar{\alpha}_t}$è¶Šæ¥è¶Šå°ï¼Œ$\sqrt{(1 - \bar{\alpha}_t)}$è¶Šæ¥è¶Šå¤§ã€‚ä¹Ÿå°±æ˜¯è¯´å™ªå£°è¶Šæ¥è¶Šå¤§äº†ã€‚

æˆ‘ä»¬å¯è§†åŒ–ä¸€ä¸‹ï¼š

```python
#@markdown visualize the DDPM noising process for different timesteps:

# Noise a batch of images to view the effect
fig, axs = plt.subplots(3, 1, figsize=(16, 10))
xb, yb = next(iter(train_dataloader))
xb = xb.to(device)[:8]
xb = xb * 2. - 1. # Map to (-1, 1)
print('X shape', xb.shape)

# Show clean inputs
axs[0].imshow(torchvision.utils.make_grid(xb[:8])[0].detach().cpu(), cmap='Greys')
axs[0].set_title('Clean X')

# Add noise with scheduler
timesteps = torch.linspace(0, 999, 8).long().to(device)
noise = torch.randn_like(xb) # << NB: randn not rand
noisy_xb = noise_scheduler.add_noise(xb, noise, timesteps)
print('Noisy X shape', noisy_xb.shape)

# Show noisy version (with and without clipping)
axs[1].imshow(torchvision.utils.make_grid(noisy_xb[:8])[0].detach().cpu().clip(-1, 1),  cmap='Greys')
axs[1].set_title('Noisy X (clipped to (-1, 1)')
axs[2].imshow(torchvision.utils.make_grid(noisy_xb[:8])[0].detach().cpu(),  cmap='Greys')
axs[2].set_title('Noisy X');
```

![image-20231118222402196](../_images/image-20231118222402196.png)

> åœ¨DDPMç‰ˆæœ¬æ˜¯ä»é«˜æ–¯åˆ†å¸ƒä¸Šæå–çš„å™ªå£°ï¼ˆæ¥è‡ªå‡å€¼0æ–¹å·®1çš„torch.randnï¼‰ï¼Œè€Œä¸æ˜¯ä¸Šé¢çš„corruptå‡½æ•°ï¼ˆ 0-1ä¹‹é—´çš„å‡åŒ€åˆ†å¸ƒï¼Œtorch.randï¼‰ã€‚
>
> `torch.randn` ç”Ÿæˆçš„æ˜¯ä»æ ‡å‡†æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·çš„éšæœºæ•°ï¼Œå› æ­¤å®ƒçš„å€¼å¯ä»¥åœ¨è´Ÿæ— ç©·åˆ°æ­£æ— ç©·ä¹‹é—´ï¼Œæ‰€ä»¥è¿™é‡Œä½¿ç”¨clipé™åˆ¶åœ¨-1ï¼Œ1ä¹‹é—´ã€‚
>
> è€Œ `torch.rand` ç”Ÿæˆçš„éšæœºæ•°èŒƒå›´åœ¨ `[0, 1)` å†…ï¼Œæ‰€ä»¥åœ¨å‰é¢ç¤ºä¾‹çš„ä»£ç ä½¿ç”¨clipé™åˆ¶åœ¨-1å’Œ1ä¹‹é—´ã€‚

ä¸Šé¢å…¬å¼å¤ªå¤æ‚äº†ï¼Œå¥½åœ¨è°ƒåº¦å™¨ï¼Œå®ƒå¸®æˆ‘ä»¬ç®€åŒ–äº†è¿™æ ·çš„è®¡ç®—ï¼Œåœ¨diffusersä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·ä½¿ç”¨ï¼š

```python
def show_images(x):
    """Given a batch of images x, make a grid and convert to PIL"""
    x = x * 0.5 + 0.5  # Map from (-1, 1) back to (0, 1)
    grid = torchvision.utils.make_grid(x)
    grid_im = grid.detach().cpu().permute(1, 2, 0).clip(0, 1) * 255
    grid_im = Image.fromarray(np.array(grid_im).astype(np.uint8))
    return grid_im

from diffusers import DDPMScheduler
noise_scheduler = DDPMScheduler(num_train_timesteps=1000)
timesteps = torch.linspace(0, 999, 8).long().to(device)
noise = torch.randn_like(xb)
noisy_xb = noise_scheduler.add_noise(xb, noise, timesteps)
print("Noisy X shape", noisy_xb.shape)
show_images(noisy_xb).resize((8 * 64, 64), resample=Image.NEAREST)
```



### è®­ç»ƒç›®æ ‡

åœ¨å‰é¢çš„ç®€å•å®ä¾‹ä¸­ï¼Œæˆ‘ä»¬è®©æ¨¡å‹å°è¯•é¢„æµ‹å»å™ªå›¾åƒã€‚åœ¨DDPMå’Œè®¸å¤šå…¶ä»–æ‰©æ•£æ¨¡å‹å®ç°ä¸­ï¼Œ**æˆ‘ä»¬è®©æ¨¡å‹å°è¯•é¢„æµ‹å»å™ªå›¾åƒã€‚åœ¨DDPMå’Œè®¸å¤šå…¶ä»–æ‰©æ•£æ¨¡å‹å®ç°ä¸­ï¼Œæ¨¡å‹åˆ™ä¼šé¢„æµ‹æŸåè¿‡ç¨‹ä¸­ä½¿ç”¨çš„å™ªå£°**ã€‚

```python
noise = torch.randn_like(xb) # randnä¸æ˜¯randï¼
noisy_x = noise_scheduler.add_noise(x, noise, timesteps)
model_prediction = model(noisy_x, timesteps).sample
loss = mse_loss(model_prediction, noise) # noise as the target
```

è¿™ä¸ªé“ç†æˆ‘åœ¨å‰é¢è¯´è¿‡ï¼Œä¸ºä»€ä¹ˆä½¿ç”¨æ‰©æ•£æ¨¡å‹çš„ç›®çš„æ˜¯é€å…¥å™ªå£°å¹²æ‰°å›¾ç‰‡ï¼Œç”Ÿæˆæ–°çš„å›¾ç‰‡ã€‚æˆ‘ä»¬åœ¨è®­ç»ƒæ—¶å€™å¯¹æ¯”ä¹Ÿæ˜¯å’Œå™ªå£°ä¹‹é—´çš„åŒºåˆ«ï¼Œè€Œä¸æ˜¯é¢„æµ‹å’ŒåŸå›¾ä¹‹é—´çš„åŒºåˆ«ï¼Œæ‰€ä»¥åŠ å…¥å™ªå£°æ›´æ˜¯æˆ‘ä»¬éœ€è¦çš„å…³æ³¨ã€‚æˆ‘ä»¬åœ¨DDPMä¸­åŠ äº†timestepï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒå¤„ç†çš„å™ªå£°æ˜¯ç´¯ç§¯çš„è¿‡ç¨‹ï¼Œç”Ÿæˆçš„å™ªå£°æœ‰æ˜æ˜¾çš„ä¹Ÿæœ‰ä¸æ˜æ˜¾çš„ï¼Œè¿™äº›ç®¡ç†å™¨è¿˜è¦æ§åˆ¶ä¸æ˜æ˜¾çš„ï¼Œåœ¨åç»­ç”Ÿæˆæ—¶å€™ç»™äºˆæ›´å¤šçš„æƒé‡ï¼Œä¸ç„¶ä½ æƒ³ï¼Œæˆ‘æŠŠä¸€åªçŒ«å˜æˆè™ï¼Œé¢å¤´æˆ‘æ²¡æœ‰å¢åŠ æ˜æ˜¾çš„å™ªå£°ï¼Œå½¢æˆä¸äº†ç‹å­—æ€ä¹ˆåŠ~

UNet2DModel æ¥å— x å’Œtimestepã€‚åè€…è¢«è½¬åŒ–ä¸ºåµŒå…¥ï¼ˆembeddingï¼‰å¹¶åœ¨å¤šä¸ªåœ°æ–¹è¾“å…¥åˆ°æ¨¡å‹ä¸­ã€‚é€šè¿‡ä¸ºæ¨¡å‹æä¾›æœ‰å…³å™ªå£°æ°´å¹³çš„ä¿¡æ¯ï¼Œå®ƒå¯ä»¥æ›´å¥½åœ°æ‰§è¡Œå…¶ä»»åŠ¡ã€‚è™½ç„¶å¯ä»¥åœ¨æ²¡æœ‰è¿™ç§æ—¶é—´æ­¥æ¡ä»¶çš„æƒ…å†µä¸‹è®­ç»ƒæ¨¡å‹ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹å®ƒä¼¼ä¹ç¡®å®æœ‰åŠ©äºæé«˜æ€§èƒ½ï¼Œå¹¶ä¸”å¤§å¤šæ•°å®ç°éƒ½åŒ…å«å®ƒï¼Œè‡³å°‘åœ¨å½“å‰çš„æ–‡çŒ®ä¸­æ˜¯è¿™æ ·ã€‚ï¼ˆç„å­¦æ¥äº†ï¼‰

ä¸‹é¢è¿™æ˜¯ PyTorch ä¸­ç»å…¸çš„ä¼˜åŒ–è¿­ä»£å¾ªç¯ï¼Œåœ¨è¿™é‡Œä¸€æ‰¹ä¸€æ‰¹çš„é€å…¥æ•°æ®ç„¶åé€šè¿‡ä¼˜åŒ–å™¨æ¥ä¸€æ­¥æ­¥æ›´æ–°æ¨¡å‹å‚æ•° - åœ¨è¿™ä¸ªæ ·ä¾‹ä¸­æˆ‘ä»¬ä½¿ç”¨å­¦ä¹ ç‡ä¸º 0.0004 çš„ AdamW ä¼˜åŒ–å™¨ã€‚

å¯¹äºæ¯ä¸€æ‰¹çš„æ•°æ®ï¼Œæˆ‘ä»¬è¦

- éšæœºå–æ ·å‡ ä¸ªè¿­ä»£å‘¨æœŸ
- æ ¹æ®é¢„è®¾ä¸ºæ•°æ®åŠ å…¥å™ªå£°
- æŠŠå¸¦å™ªæ•°æ®å’Œtimestepsé€å…¥æ¨¡å‹
- ä½¿ç”¨ MSE ä½œä¸ºæŸå¤±å‡½æ•°æ¥æ¯”è¾ƒåŠ å…¥çš„å™ªå£°ä¸æ¨¡å‹é¢„æµ‹ç»“æœå·®è·åœ¨å“ªã€‚ç»“æœè¶Šå°è¶Šå¥½ï¼Œè¯´æ˜è¿™ä¸ªå™ªå£°æˆ‘ä»¬èƒ½æŠŠæ§ä½ï¼Œæˆ‘ä»¬å°±èƒ½åœ¨ç°æœ‰åŸºç¡€ä¸Šæ¥æ“åˆ€ï¼ŒæŠŠå®ƒæ•´å®¹ã€‚
- é€šè¿‡`loss.backward ()`ä¸`optimizer.step ()`æ¥æ›´æ–°æ¨¡å‹å‚æ•°

```python
# Set the noise scheduler
noise_scheduler = DDPMScheduler(
    num_train_timesteps=1000, beta_schedule="squaredcos_cap_v2"
)

# Training loop
optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4)

losses = []

for epoch in range(30):
    for step, batch in enumerate(train_dataloader):
        clean_images = batch["images"].to(device)
        # Sample noise to add to the images
        noise = torch.randn(clean_images.shape).to(clean_images.device)
        bs = clean_images.shape[0]

        # Sample a random timestep for each image
        # åˆ†ä¸ºbatsizeä»½
        timesteps = torch.randint(
            0, noise_scheduler.num_train_timesteps, (bs,), device=clean_images.device
        ).long()

        # Add noise to the clean images according to the noise magnitude at each timestep
        noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)

        # Get the model prediction
        noise_pred = model(noisy_images, timesteps, return_dict=False)[0]

        # Calculate the loss
        loss = F.mse_loss(noise_pred, noise)
        loss.backward(loss)
        losses.append(loss.item())

        # Update the model parameters with the optimizer
        optimizer.step()
        optimizer.zero_grad()

    if (epoch + 1) % 5 == 0:
        loss_last_epoch = sum(losses[-len(train_dataloader) :]) / len(train_dataloader)
        print(f"Epoch:{epoch+1}, loss: {loss_last_epoch}")
```



### é‡‡æ ·

æœ‰ä¸€ä¸ªæ¨¡å‹å¯ä»¥ç”¨æ¥é¢„æµ‹åœ¨å¸¦å™ªæ ·æœ¬ä¸­çš„å™ªå£°ï¼Œæˆ‘ä»¬æ€ä¹ˆç”¨å®ƒæ¥ç”Ÿæˆå›¾åƒå‘¢ï¼Ÿ

```python
# 1. å»ºç«‹ä¸€ä¸ªç®¡é“ï¼š
from diffusers import DDPMPipeline
image_pipe = DDPMPipeline(unet=model, scheduler=noise_scheduler)
pipeline_output = image_pipe()
pipeline_output.images[0]
#ä¿å­˜ç®¡é“ï¼šimage_pipe.save_pretrained("my_pipeline")

#2. å†™ä¸€ä¸ªå–æ ·å¾ªç¯
# Random starting point (8 random images):
sample = torch.randn(8, 3, 32, 32).to(device)

for i, t in enumerate(noise_scheduler.timesteps):

    # Get model pred
    with torch.no_grad():
        residual = model(sample, t).sample

    # Update sample with step
    sample = noise_scheduler.step(residual, t, sample).prev_sample

show_images(sample)
```

æœ€ç†æƒ³çš„çŠ¶æ€æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ç»™å…¥çº¯å™ªå£°ï¼Œå°±å¸Œæœ›æ¨¡å‹èƒ½ä¸€æ­¥å°±è¾“å‡ºä¸€ä¸ªä¸å¸¦å™ªå£°çš„å¥½å›¾åƒã€‚ä½†æ˜¯è¿™é€šå¸¸è¡Œä¸é€šã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬åœ¨æ¨¡å‹é¢„æµ‹çš„åŸºç¡€ä¸Šä¸€æ­¥ä¸€æ­¥ï¼Œè¿­ä»£ç€æ¥æ¯æ¬¡å»é™¤ä¸€ç‚¹ç‚¹å™ªå£°ã€‚

è¿™é‡Œä¸å‰é¢çš„å·®ä¸å¤šï¼Œå› ä¸ºé‡‡æ ·å°±æ˜¯å»é™¤å™ªå£°ï¼Œä½†è¿™é‡Œä¸æ˜¯è¯´è¿˜åŸå›¾åƒï¼Œè€Œæ˜¯ç”Ÿæˆæ–°çš„å›¾åƒäº†ã€‚

åªä¸è¿‡æ˜¯é‡‡æ ·çš„ç­–ç•¥ä¸åŒï¼Œè¿™è·Ÿä¸åŒçš„æ‰©æ•£æ¨¡å‹æœ‰å…³
